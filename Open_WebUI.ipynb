{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Axenide/Open-WebUI-Colab/blob/main/Open_WebUI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Open WebUI\n",
        "This is my first notebook so it is probably really messy. Anyways, I wanted to give people the opportunity to try Open WebUI without the need of high-end hardware.\n",
        "\n",
        "Check my [GitHub](https://github.com/Axenide) ðŸ‘ˆ"
      ],
      "metadata": {
        "id": "9AAJzmDMhE6C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencies\n",
        "Here we will install Ollama:"
      ],
      "metadata": {
        "id": "cEdfep4Jhh6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ],
      "metadata": {
        "id": "75u7Td2HV957"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing Open WebUI\n",
        "Now, Open WebUI needs Python 3.11 so we have to install it in a venv and generate the script to run it asynchronously because Colab won't let you run multiple codeblocks."
      ],
      "metadata": {
        "id": "AksDFR8miRaL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "JpgA4UIQnGA_"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install -y python3.11 python3.11-venv python3.11-dev\n",
        "\n",
        "# Create and activate a virtual environment using Python 3.11\n",
        "!python3.11 -m venv venv\n",
        "!source venv/bin/activate\n",
        "\n",
        "# Upgrade pip within the virtual environment\n",
        "!venv/bin/python -m pip install --upgrade pip\n",
        "\n",
        "# Install Open WebUI within the virtual environment\n",
        "!venv/bin/pip install open-webui\n",
        "\n",
        "# Create a script to start both servers asynchronously and expose them using localtunnel\n",
        "with open('start_servers.py', 'w') as f:\n",
        "    f.write('''\n",
        "import subprocess\n",
        "import threading\n",
        "import os\n",
        "import time\n",
        "\n",
        "def start_ollama():\n",
        "    subprocess.run(['ollama', 'serve'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "def start_open_webui():\n",
        "    subprocess.run(['venv/bin/open-webui', 'serve', '--port', '8081'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "# Start servers in separate threads\n",
        "threading.Thread(target=start_ollama).start()\n",
        "time.sleep(5)\n",
        "threading.Thread(target=start_open_webui).start()\n",
        "''')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Time to start the servers!\n",
        "We will run both Open WebUI and Ollama servers and get the public URL using Pinggy.\n",
        "\n",
        "To download models, navigate to the Ollama Settings in the Connections tab. Alternatively, you can also download models directly by typing their tag in the model selection dropdown (e.g. mistral-nemo). This action will create a button labeled \"Pull [Model Name]\" for downloading."
      ],
      "metadata": {
        "id": "o3Q5RiLl668K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute the script\n",
        "!venv/bin/python start_servers.py & sleep 20; echo | ssh -o StrictHostKeyChecking=no -p 443 -R0:localhost:8081 qr@a.pinggy.io"
      ],
      "metadata": {
        "id": "0MQ4Ub3X7BcR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}